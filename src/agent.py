import os
import json
import glob
import google.generativeai as genai_v1
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

PROJECT_ROOT = os.path.join(os.path.dirname(__file__), '..')
# Tabela de pre√ßos por 1M tokens (USD)
PRICING_USD_PER_1M = {
    "gemini-3.1-pro-preview":   {"input": 3.50, "output": 10.50},
    "gemini-3-flash-preview":   {"input": 0.70, "output": 2.10},
    "gemini-2.5-flash-lite": {"input": 0.10, "output": 0.40},
    # Modelos gratuitos (via Puter, OpenRouter, Z.ai, Kimi)
    "gpt-4o-mini": {"input": 0.00, "output": 0.00},
    "x-ai/grok-4-1-fast": {"input": 0.00, "output": 0.00},
    "moonshot-v1-8k": {"input": 0.00, "output": 0.00},
    "glm-4.5-flash": {"input": 0.00, "output": 0.00},
    "deepseek/deepseek-r1-0528:free": {"input": 0.00, "output": 0.00},
    "google/gemma-3-27b:free": {"input": 0.00, "output": 0.00},
    "meta-llama/llama-4-scout:free": {"input": 0.00, "output": 0.00},
    "meta-llama/llama-3.1-70b-instruct": {"input": 0.00, "output": 0.00},
    "claude-3-5-sonnet": {"input": 0.00, "output": 0.00},
}
USD_TO_BRL = 5.80

MODELOS_DISPONIVEIS = {
    "üöÄ Gemini 3 Flash Preview [PAGO] ‚Äî ~R$0,02/roteiro": "gemini-3-flash-preview",
    "üëë Gemini 3.1 Pro Preview [PAGO] ‚Äî ~R$0,19/roteiro": "gemini-3.1-pro-preview",
    "üí∞ Gemini 2.5 Flash-Lite [PAGO] ‚Äî ~R$0,005/roteiro": "gemini-2.5-flash-lite",
    "üî• Grok 4.1 Fast [GR√ÅTIS] ‚Äî Criativo (Puter)": "puter/x-ai/grok-4-1-fast",
    "ü§ñ GPT-4o Mini [GR√ÅTIS] ‚Äî Flu√≠do (Puter)": "puter/gpt-4o-mini",
    "üá®üá≥ GLM-4.5 Flash [GR√ÅTIS] ‚Äî Ficha T√©cnica (Z.ai)": "zai/glm-4.5-flash"
}

MODELOS_DESCRICAO = {
    "gemini-3.1-pro-preview": "[O SUPERIOR] (Fev/2026) Intelig√™ncia de ponta absoluta. Melhor estrutura√ß√£o, obedi√™ncia de formata√ß√£o e racioc√≠nio hiper avan√ßado. Perfeito para 3D. Custo: ~R$ 0,19.",
    "gemini-3-flash-preview": "[O √ÅGIL] (Dez/2025) R√°pido e muito preciso na interpreta√ß√£o. Vers√£o ultra-otimizada. Custo: ~R$ 0,02.",
    "gemini-2.5-flash-lite": "[CUSTO-BENEF√çCIO] (2025) Barato e r√°pido. √ìtimo com fon√©tica e resume bem as cenas sem perder a ess√™ncia. Custo: ~R$ 0,005.",
    "puter/gpt-4o-mini": "[O DESOBEDIENTE] (2024) Bom nos benef√≠cios, mas costuma quebrar regras de cabe√ßalho e errar pron√∫ncias. Use como estepe.",
    "puter/x-ai/grok-4-1-fast": "[O VENCEDOR / O HUMANO] (2025) O meio termo perfeito. Transforma dados frios em textos diretos, din√¢micos e naturais para a Lu. Prioridade gratuita.",
    "zai/glm-4.5-flash": "[LENTO E PRECISO] (2025) N√£o alucina. Excelente para fichas ultra-t√©cnicas (ferramentas), mas a sua lentid√£o inviabiliza lotes grandes."
}
PROVIDER_KEY_MAP = {
    "gemini": "GEMINI_API_KEY",
    "openai": "OPENAI_API_KEY",
    "puter": "PUTER_API_KEY",
    "openrouter": "OPENROUTER_API_KEY",
    "zai": "ZAI_API_KEY",
    "kimi": "KIMI_API_KEY",
}

def calcular_custo_brl(model_id, tokens_in, tokens_out):
    """Calcula o custo estimado em BRL com base nos tokens consumidos."""
    pricing = PRICING_USD_PER_1M.get(model_id, PRICING_USD_PER_1M["gemini-3-flash-preview"])
    custo_usd = (tokens_in / 1_000_000 * pricing["input"]) + (tokens_out / 1_000_000 * pricing["output"])
    return round(custo_usd * USD_TO_BRL, 6)

class RoteiristaAgent:
    def __init__(self, supabase_client=None, model_id="gemini-3-flash-preview", table_prefix="nw_"):
        self.model_id = model_id
        self.table_prefix = table_prefix
        self.supabase = supabase_client
        self.client_gemini = None
        self.client_openai = None
        self.provider = "gemini"

        if self.model_id.startswith("gemini"):
            self.provider = "gemini"
            api_key = os.environ.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
            if not api_key:
                raise ValueError("GEMINI_API_KEY n√£o encontrada!")
            genai_v1.configure(api_key=api_key)
            self.client_gemini = genai_v1.GenerativeModel(self.model_id)
        elif self.model_id.startswith("puter/"):
            self.provider = "puter"
            puter_key = os.environ.get("PUTER_API_KEY")
            if not puter_key:
                raise ValueError("PUTER_API_KEY n√£o encontrada!")
            self.client_openai = OpenAI(
                api_key=puter_key,
                base_url="https://api.puter.com/puterai/openai/v1/"
            )
            self.model_id = self.model_id.replace("puter/", "")
        elif self.model_id.startswith("openai/"):
            self.provider = "openai"
            openai_key = os.environ.get("OPENAI_API_KEY")
            if not openai_key:
                raise ValueError("OPENAI_API_KEY n√£o encontrada!")
            self.client_openai = OpenAI(api_key=openai_key)
            self.model_id = self.model_id.replace("openai/", "")
        elif self.model_id.startswith("openrouter/"):
            self.provider = "openrouter"
            or_key = os.environ.get("OPENROUTER_API_KEY")
            if not or_key:
                raise ValueError("OPENROUTER_API_KEY n√£o encontrada!")
            self.client_openai = OpenAI(
                api_key=or_key,
                base_url="https://openrouter.ai/api/v1"
            )
            self.model_id = self.model_id.replace("openrouter/", "")
        elif self.model_id.startswith("puter/"):
            self.provider = "puter"
            puter_key = os.environ.get("PUTER_API_KEY")
            if not puter_key:
                raise ValueError("PUTER_API_KEY n√£o encontrada!")
            self.client_openai = OpenAI(
                api_key=puter_key,
                base_url="https://api.puter.com/puterai/openai/v1/"
            )
            self.model_id = self.model_id.replace("puter/", "")
        elif self.model_id.startswith("zai/"):
            self.provider = "zai"
            zai_key = os.environ.get("ZAI_API_KEY")
            if not zai_key:
                raise ValueError("ZAI_API_KEY n√£o encontrada!")
            self.client_openai = OpenAI(
                api_key=zai_key,
                base_url="https://api.z.ai/api/paas/v4/"
            )
            self.model_id = self.model_id.replace("zai/", "")
        elif self.model_id.startswith("kimi/"):
            self.provider = "kimi"
            kimi_key = os.environ.get("KIMI_API_KEY")
            if not kimi_key:
                raise ValueError("KIMI_API_KEY n√£o encontrada!")
            self.client_openai = OpenAI(
                api_key=kimi_key,
                base_url="https://api.moonshot.ai/v1"
            )
            self.model_id = self.model_id.replace("kimi/", "")

        # Carrega toda a base de conhecimento est√°tica (Apenas prompts e fon√©tica base)
        self.system_prompt = self._load_file(
            os.path.join(PROJECT_ROOT, ".agents", "system_prompt.txt"), ""
        )
        self.phonetics = self._load_json(
            os.path.join(PROJECT_ROOT, "kb", "phonetics.json"), {}
        )
        # Ouro e Calibragem agora s√£o 100% din√¢micos via Supabase
        self.few_shot_examples = [] 
        
        # Carrega documentos de contexto (.md) da KB
        self.context_docs = self._load_all_md_from_kb()

    def _load_file(self, filepath, fallback):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            return fallback

    def _load_json(self, filepath, fallback):
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return fallback

    def _load_all_md_from_kb(self):
        """Carrega todos os .md da pasta kb/ como contexto estrat√©gico."""
        docs = []
        kb_path = os.path.join(PROJECT_ROOT, "kb")
        for md_file in glob.glob(os.path.join(kb_path, "*.md")):
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    # Limita cada doc a 4000 chars para n√£o estourar o contexto
                    docs.append(content[:4000])
            except Exception:
                pass
        return docs

    def _fetch_supabase_context(self):
        """Busca aprendizado din√¢mico no Supabase."""
        sb_parts = []
        if not self.supabase:
            return ""
        
        try:
            # 1. Roteiros Ouro (O "Norte" da Reda√ß√£o - Exemplos de Elite)
            res_ouro = self.supabase.table(f"{self.table_prefix}roteiros_ouro").select("*").order('criado_em', desc=True).limit(5).execute()
            if res_ouro.data:
                sb_parts.append("\n**REFER√äNCIAS DE ELITE (ESTE √â O PADR√ÉO OURO A SER SEGUIDO):**")
                for r in res_ouro.data:
                    sb_parts.append(f"- Produto: {r['titulo_produto']}\n  Roteiro Perfeito (Target): {r['roteiro_perfeito']}")

            # 2. Ajustes de Persona (SHARED)
            res_pers = self.supabase.table("nw_treinamento_persona_lu").select("*").limit(5).execute()
            if res_pers.data:
                sb_parts.append("\n**AJUSTES DE PERSONA (LI√á√ïES APRENDIDAS):**")
                for p in res_pers.data:
                    sb_parts.append(f"- Pilar: {p['pilar_persona']}\n  Erro Anterior: {p['erro_cometido']}\n  Corre√ß√£o Master: {p['texto_corrigido_humano']}")

            # 3. Novas Regras Fon√©ticas (SHARED ACROSS MODES)
            res_fon = self.supabase.table("nw_treinamento_fonetica").select("*").execute()
            if res_fon.data:
                sb_parts.append("\n**NOVAS REGRAS DE FON√âTICA (OBRIGAT√ìRIO):**")
                for f in res_fon.data:
                    sb_parts.append(f"- {f['termo_errado']} -> ({f['termo_corrigido']})")
                    
            # 4. Estruturas Aprovadas (Aberturas e Fechamentos/CTAs)
            res_est = self.supabase.table(f"{self.table_prefix}treinamento_estruturas").select("*").execute()
            if res_est.data:
                sb_parts.append("\n**ESTRUTURAS APROVADAS PARA INSPIRA√á√ÉO (HOOKS E CTAs):**")
                for est in res_est.data:
                    sb_parts.append(f"- [{est['tipo_estrutura']}] {est['texto_ouro']}")
                    
            # 5. Nuances de Linguagem (O que evitar e como melhorar)
            res_nuan = self.supabase.table(f"{self.table_prefix}treinamento_nuances").select("*").limit(5).order('criado_em', desc=True).execute()
            if res_nuan.data:
                sb_parts.append("\n**NUANCES E REFINAMENTO DE ESTILO (LI√á√ïES DE REDA√á√ÉO):**")
                for n in res_nuan.data:
                    refinamento = f"- EVITE: '{n['frase_ia']}'\n  POR QUE: {n['analise_critica']}"
                    if n.get('exemplo_ouro'):
                        refinamento += f"\n  FORMA IDEAL: '{n['exemplo_ouro']}'"
                    sb_parts.append(refinamento)

            # 6. Mem√≥ria de Calibragem (Li√ß√µes Recentes da Calibragem)
            res_fb = self.supabase.table(f"{self.table_prefix}roteiros_ouro").select("aprendizado").neq("aprendizado", "null").order('criado_em', desc=True).limit(8).execute()
            if res_fb.data:
                valid_mems = [f for f in res_fb.data if f.get('aprendizado') and f['aprendizado'].strip()]
                if valid_mems:
                    sb_parts.append("\n**LI√á√ïES RECENTES DA CALIBRAGEM (N√ÉO REPITA ESTES ERROS):**")
                    for fb in valid_mems:
                        sb_parts.append(f"- {fb['aprendizado']}")

            # 7. Calibragem Visual (Descri√ß√£o de Imagens)
            res_img = self.supabase.table(f"{self.table_prefix}treinamento_imagens").select("*").limit(5).order('criado_em', desc=True).execute()
            if res_img.data:
                sb_parts.append("\n**DIRETRIZES VISUAIS (COMO DESCREVER IMAGENS):**")
                for img in res_img.data:
                    sb_parts.append(f"- EVITE: '{img['descricao_ia']}'\n  USE PREFERENCIALMENTE: '{img['descricao_humano']}'\n  MOTIVO: {img['aprendizado']}")
        except Exception as e:
            print(f"Error fetching Supabase context: {e}")
            
        return "\n".join(sb_parts)

    def _build_context(self):
        """Monta o contexto completo: Prompt + KB Estrat√©gica + Fon√©tica + Few-Shot + Supabase."""
        parts = []

        # 1. System Prompt (Regras de Ouro do Breno)
        if self.system_prompt:
            parts.append(self.system_prompt)

        # 2. Contexto estrat√©gico do mercado brasileiro e persona Lu
        if self.context_docs:
            parts.append("\n**CONTEXTO ESTRAT√âGICO (MERCADO BRASILEIRO E PERSONA LU):**")
            parts.append("Use este conhecimento para adaptar o tom e as refer√™ncias do roteiro:")
            for doc in self.context_docs:
                parts.append(doc)

        # 3. Dicion√°rio de fon√©tica (Est√°tico)
        if self.phonetics:
            parts.append("\n**DICION√ÅRIO DE FON√âTICA BASE (PADR√ÉO):**")
            for sigla, pronuncia in self.phonetics.items():
                parts.append(f"- {sigla} -> ({pronuncia})")

        # 4. Few-Shot Learning (Est√°tico)
        if self.few_shot_examples:
            parts.append("\n**EXEMPLOS HIST√ìRICOS DE REFER√äNCIA:**")
            for ex in self.few_shot_examples:
                parts.append(f"\n--- EXEMPLO: {ex.get('produto', '')} ---")
                parts.append(f"‚ùå TEXTO IA: {ex.get('output_antes_ia_ruim', '')}")
                parts.append(f"‚úÖ COMO O BRENO QUER: {ex.get('output_depois_breno_aprovado', '')}")

        # 5. Aprendizado em Tempo Real (Supabase)
        supabase_context = self._fetch_supabase_context()
        if supabase_context:
            parts.append(supabase_context)

        return "\n".join(parts)

    def gerar_memoria_calibracao(self, ia_text, breno_text):
        """Analisa a diferen√ßa entre o texto da IA e o aprovado, e extrai a 'li√ß√£o'. Usa fallback multi-provedor."""
        prompt = (
            "Voc√™ √© um Analista de Reda√ß√£o Publicit√°ria S√™nior comparando DUAS vers√µes de um roteiro de v√≠deo.\n\n"
            "VERS√ÉO A (Gerada pela IA):\n"
            f"{ia_text}\n\n"
            "VERS√ÉO B (Aprovada pelo Humano / Breno):\n"
            f"{breno_text}\n\n"
            "Sua tarefa: N√£o descreva pequenas trocas de palavras. Extraia o PADR√ÉO T√âCNICO DE ESCRITA que o humano aplicou.\n"
            "Exemplos de padr√µes: 'Encurtar ganchos iniciais', 'Remover termos t√©cnicos complexos', 'Focar no benef√≠cio emocional em vez da ficha t√©cnica', 'Usar tom mais imperativo no fechamento'.\n\n"
            "Responda em NO M√ÅXIMO 1 frase objetiva (m√°ximo 150 caracteres). "
            "Use o formato estrito: 'PADR√ÉO OBSERVADO: [descreva a regra t√©cnica de reda√ß√£o aplicada].'\n"
            "N√ÉO use met√°foras. Seja puramente t√©cnico e direto."
        )

        # üü¢ OP√á√ÉO 1: PUTER (Grok 4.1 Fast ‚Äî Gr√°tis)
        api_key_puter = os.environ.get("PUTER_API_KEY")
        if api_key_puter:
            try:
                from openai import OpenAI as OpenAIClient
                client = OpenAIClient(api_key=api_key_puter, base_url="https://api.puter.com/puterai/openai/v1/")
                response = client.chat.completions.create(
                    model="x-ai/grok-4-1-fast",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3
                )
                print("[OK] Memoria de calibragem gerada via Puter (grok-4-1-fast)")
                return response.choices[0].message.content.replace('\n', ' ').strip()
            except Exception as e:
                print(f"[ERROR] Erro Puter Memoria: {e}")

        # üîµ OP√á√ÉO 2: OPENROUTER (DeepSeek R1 ‚Äî Gr√°tis)
        api_key_or = os.environ.get("OPENROUTER_API_KEY")
        if api_key_or:
            try:
                from openai import OpenAI as OpenAIClient
                client = OpenAIClient(api_key=api_key_or, base_url="https://openrouter.ai/api/v1")
                response = client.chat.completions.create(
                    model="deepseek/deepseek-r1-0528:free",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3
                )
                print("[OK] Memoria de calibragem gerada via OpenRouter (deepseek-r1)")
                return response.choices[0].message.content.replace('\n', ' ').strip()
            except Exception as e:
                print(f"[ERROR] Erro OpenRouter Memoria: {e}")

        # üü° OP√á√ÉO 3: GEMINI (se a key funcionar)
        api_key_gemini = os.environ.get("GEMINI_API_KEY")
        if api_key_gemini:
            try:
                from google.genai import types
                client = genai_v1.Client(api_key=api_key_gemini)
                response = client.models.generate_content(
                    model='gemini-3-flash-preview',
                    contents=prompt,
                    config=types.GenerateContentConfig(temperature=0.3)
                )
                print("[OK] Memoria de calibragem gerada via Gemini (3-flash-preview)")
                return response.text.replace('\n', ' ').strip()
            except Exception as e:
                print(f"[ERROR] Erro Gemini Memoria: {e}")

        return "Erro: Nenhum provedor dispon√≠vel para gerar mem√≥ria de calibragem."

    def gerar_roteiro(self, scraped_data, modo_trabalho="NW (NewWeb)", mes="MAR", data_roteiro=None, codigo=None, nome_produto=None, sub_skus=None, video_url=None):
        """Envia a requisi√ß√£o para o Gemini gerar o roteiro. Suporta Multimodal e Modos de Trabalho."""
        context = self._build_context()

        # Verifica se o input tem imagem (novo fluxo do scraper)
        if isinstance(scraped_data, dict):
            text_data = scraped_data.get("text", "")
            images_list = scraped_data.get("images", [])
        else:
            text_data = str(scraped_data)
            images_list = []
            
        # Roteamento b√°sico de Prompt baseado no Modo (Expans√£o Futura)
        diretriz_modo = f"Crie um roteiro focado no formato padr√£o NewWeb (descri√ß√£o rica e completa)."
        
        # INJE√á√ÉO DAS T√ÅTICAS NW LU (M√™s e Cena Obrigat√≥ria)
        if "NW" in modo_trabalho:
            data_str = data_roteiro if data_roteiro else "[DATA_ATUAL]"
            # Garante que o c√≥digo tenha 9 d√≠gitos (preenche com 0 √† direita)
            cod_str = str(codigo).strip() if codigo else "[C√ìDIGO_AQUI]"
            if cod_str.isdigit() and len(cod_str) < 9:
                cod_str = cod_str.ljust(9, '0')
            
            sub_skus_str = f" {sub_skus}" if (sub_skus and str(sub_skus).lower() != 'nan') else ""
            video_ref_str = f"\n   {video_url}" if (video_url and str(video_url).lower() != 'nan') else ""
            
            diretriz_modo += (
                f"\n\nüö® REGRA ABSOLUTA DE FORMATA√á√ÉO E ESTRUTURA (NW LU):\n"
                f"1. O TEXTO DEVE COME√áAR COM O CABE√áALHO EXATAMENTE ABAIXO (PROIBIDO COPIAR A DATA OU M√äS DOS EXEMPLOS, USE EXATAMENTE O QUE EST√Å AQUI):\n"
                f"   Cliente: Magalu\n"
                f"   Roteirista: Tiago Fernandes - Data: {data_str}\n"
                f"   Produto: NW LU {mes} {cod_str}{sub_skus_str} [INSERIR NOME RESUMIDO DO PRODUTO AQUI]{video_ref_str}\n"
                f"2. A CENA 1 (Primeira cena do v√≠deo) DEVE OBRIGATORIAMENTE mostrar a 'Lu' em a√ß√£o, interagindo com o produto ou apresentando-o.\n"
                f"3. A partir da CENA 2, CORTE para imagens do produto. REGRA CR√çTICA DE IMAGEM: √â ESTRITAMENTE PROIBIDO sugerir a√ß√µes humanas nas Colunas de Imagem (ex: 'm√£o segurando o celular', 'pessoa bebendo caf√©', 'cliente usando'). O v√≠deo NW √© feito APENAS com fotos est√°ticas do fornecedor, anima√ß√µes gr√°ficas (GCs) e recortes do v√≠deo oficial. IMAGENS 100% LIMPAS DE HUMANOS."
            )

        if "SOCIAL" in modo_trabalho:
            diretriz_modo = f"ATEN√á√ÉO: Este formato √© para SOCIAL (Reels/TikTok). O roteiro deve ser EXTREMAMENTE curto, din√¢mico e focado em reten√ß√£o nos primeiros 3 segundos."
        elif "3D" in modo_trabalho:
            diretriz_modo += (
                f"\n\nATEN√á√ÉO: Este formato √© para V√çDEO 3D. O estilo de v√≠deo ser√° feito APENAS com cenas 3D autorais da Magalu. "
                f"Por isso, o roteiro PRECISA ter uma sequ√™ncia L√ìGICA natural, fluida e cont√≠nua. N√ÉO pode ficar 'picotado' "
                f"como o tradicional NewWeb.\nFoque muito em descrever as texturas, cores exatas, reflexos e √¢ngulos de c√¢mera importantes para o time de modelagem."
            )
        elif "Review" in modo_trabalho:
            diretriz_modo += f"\n\nATEN√á√ÉO: Este formato √© um REVIEW. Foque em pr√≥s, contras, uso pr√°tico di√°rio e uma opini√£o direta para quem vai gravar no est√∫dio."

        final_prompt = (
            f"{context}\n\n"
            f"**MODO DE TRABALHO SOLICITADO:** {modo_trabalho}\n"
            f"-> {diretriz_modo}\n\n"
            f"**CONTEXTO DO PRODUTO (INPUT TEXTUAL E/OU VISUAL):**\n{text_data}\n\n"
            f"**INSTRU√á√ÉO FINAL:**\n"
            f"1. Gere o roteiro no FORMATO DE SA√çDA OBRIGAT√ìRIO.\n"
            f"2. ENCARNE A PERSONA DA LU: Seja acolhedora, direta e prestativa. Siga RIGOROSAMENTE as Regras de Ouro do Estilo Breno e o Contexto Estrat√©gico.\n"
            f"3. Se houverem imagens fornecidas, extraia o m√°ximo de detalhes visuais (cor, textura, design) para enriquecer o roteiro.\n"
            f"4. Imite fielmente o estilo dos exemplos APROVADOS.\n"
            f"5. Use 'pra' no lugar de 'para'. Coloque a marca entre v√≠rgulas.\n"
            f"6. **ENRIQUECIMENTO DE CONTEXTO:** Para produtos mundialmente conhecidos, adicione detalhes t√©cnicos ou curiosidades RELEVANTES que n√£o estejam na ficha, MAS sem alongar o roteiro desnecessariamente.\n"
            f"7. **REGRA FONTE EXTERNA (CR√çTICA):** Se o input contiver uma linha 'FONTE EXTERNA: [URL]', voc√™ DEVE OBRIGATORIAMENTE adicionar ao final do seu roteiro uma linha vazia seguida de: 'Fonte Externa: [URL]'.\n"
            f"8. **PROIBI√á√ÉO DE REDUND√ÇNCIA (MUITO IMPORTANTE):** O roteiro deve ser direto e din√¢mico. N√ÉO REPITA o mesmo assunto, benef√≠cio ou caracter√≠stica t√©cnica em par√°grafos separados de forma desnecess√°ria. Cada cena/fala deve trazer uma informa√ß√£o NOVA.\n"
            f"9. **COMPLETUDE OBJETIVA E SA√öDE:** Seja din√¢mico, mas N√ÉO omita em hip√≥tese alguma diferenciais invis√≠veis vitais para o consumidor presentes na Ficha T√©cnica (ex: prote√ß√£o anti√°caro/antimofo/antifungo, antibacteriano, acess√≥rios extras). Transforme essas caracter√≠sticas essenciais em benef√≠cios claros para a sa√∫de e usabilidade do cliente, sem enrola√ß√£o.\n"
            f"10. **REGRA DA COMPOSI√á√ÉO E KITS (ACESS√ìRIOS):** Se o produto for um conjunto, kit ou cozinha completa, voc√™ DEVE listar explicitamente as pe√ßas principais que o comp√µem (ex: balc√£o, a√©reo, nicho, paneleiro) exatamente como constam no campo 'Composi√ß√£o' ou na descri√ß√£o, n√£o apenas diga '√© uma cozinha'.\n"
            f"11. **PRON√öNCIA DE ESTRANGEIRISMOS:** Sempre que houver nomes de marcas estrangeiras, tecnologias (Core i7, QLED, OLED, Magsafe) ou palavras dif√≠ceis, preveja como um brasileiro falaria e insira a pron√∫ncia em par√™nteses. Exemplo: OPPO (√≥-p√¥), Reno14 (r√™-no quatorze).\n"
            f"12. **PROIBI√á√ÉO DE SCRIPTS HIPOT√âTICOS:** Se o contexto do produto for insuficiente, N√ÉO gere roteiro. Responda: 'ERRO: Dados insuficientes do produto para gera√ß√£o autom√°tica.'"
        )

        if self.client_gemini:
            contents = [final_prompt]
            if images_list:
                for img_dict in images_list:
                    img_bytes = img_dict.get("bytes")
                    img_mime = img_dict.get("mime")
                    if img_bytes and img_mime:
                        contents.append({
                            "mime_type": img_mime,
                            "data": img_bytes
                        })

            # Chamada via SDK v1
            response = self.client_gemini.generate_content(contents)
            roteiro = response.text
            
            # M√©tricas via v1
            tokens_in = len(final_prompt) // 4
            tokens_out = len(roteiro) // 4
        
        elif self.client_openai:
            messages = [{"role": "user", "content": final_prompt}]
            # Para modelos OpenAI/Puter, o envio de imagens (vision) tem uma estrutura diferente.
            # Como a documenta√ß√£o prim√°ria do Puter para Grok Fast n√£o deixa claro o suporte a imagens,
            # passaremos apenas texto por enquanto, a n√£o ser que o modelo suporte e tenhamos url.
            
            response = self.client_openai.chat.completions.create(
                model=self.model_id,
                messages=messages
            )
            roteiro = response.choices[0].message.content
            
            tokens_in = response.usage.prompt_tokens if hasattr(response, 'usage') else 0
            tokens_out = response.usage.completion_tokens if hasattr(response, 'usage') else 0
        
        else:
            raise Exception("Nenhum cliente LLM configurado v√°lido.")

        # --- POST-PROCESSING ENFORCEMENT ---
        # For√ßa o cabe√ßalho correto ignorando as alucina√ß√µes de c√≥pia de exemplos do LLM
        if "NW" in modo_trabalho:
            try:
                import re
                linhas = roteiro.split('\n')
                for i, linha in enumerate(linhas):
                    if "Cliente: Magalu" in linha.replace('*', ''):
                        data_s = data_roteiro if data_roteiro else "[DATA_ATUAL]"
                        cod_s = str(codigo).strip() if codigo else "[C√ìDIGO_AQUI]"
                        if cod_s.isdigit() and len(cod_s) < 9: cod_s = cod_s.ljust(9, '0')
                        sub_s = f" {sub_skus}" if (sub_skus and str(sub_skus).lower() != 'nan') else ""
                        vid_s = f"\n   {video_url}" if (video_url and str(video_url).lower() != 'nan') else ""
                        
                        linhas[i] = "Cliente: Magalu"
                        if i + 1 < len(linhas):
                            linhas[i+1] = f"Roteirista: Tiago Fernandes - Data: {data_s}"
                        if i + 2 < len(linhas):
                            prod_str = linhas[i+2].replace('**', '').replace('Produto:', '').strip()
                            nome_purificado = re.sub(r'^(NW\s*(3D)?\s*LU\s*[A-Z]{3}\s*\d+\s+)', '', prod_str)
                            linhas[i+2] = f"Produto: NW LU {mes} {cod_s}{sub_s} {nome_purificado}{vid_s}"
                        roteiro = "\n".join(linhas)
                        break
            except Exception as e:
                print(f"[WARN] Error enforcing header: {e}")

        custo_brl = calcular_custo_brl(self.model_id, tokens_in, tokens_out)

        return {
            "roteiro": roteiro,
            "model_id": self.model_id,
            "tokens_in": tokens_in,
            "tokens_out": tokens_out,
            "custo_brl": custo_brl
        }

    def _extract_json(self, text):
        """Extrai JSON de uma resposta que pode conter markdown wrappers (```json ... ```)."""
        import re
        # Tenta parsear direto
        try:
            return json.loads(text)
        except (json.JSONDecodeError, TypeError):
            pass
        # Tenta extrair de blocos ```json ... ``` ou ``` ... ```
        match = re.search(r'```(?:json)?\s*\n?({.*?})\s*\n?```', text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass
        # Tenta encontrar o primeiro { ... } na resposta
        match = re.search(r'(\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\})', text, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                pass
        raise ValueError(f"N√£o foi poss√≠vel extrair JSON da resposta: {text[:200]}")

    def analisar_calibracao(self, original, final, categories_list=[], codigo_original=""):
        """
        Realiza a an√°lise de calibragem de qualidade usando LLMs gratuitos.
        Cadeia de fallback: Puter (Grok 4.1 Fast) ‚Üí OpenRouter (DeepSeek V3) ‚Üí Gemini (2.5 Flash).
        """
        # Define um ID de fallback seguro (o primeiro da lista ou 0)
        fallback_id = categories_list[0]['id'] if categories_list else 1
        # Formata a lista de categorias para o prompt
        cat_str = "\n".join([f"- ID {c['id']}: {c['nome']}" for c in categories_list]) if categories_list else "Gen√©rico (ID 1)"

        sys_prompt = (
            "Voc√™ √© um Editor S√™nior de Reda√ß√£o Publicit√°ria e Especialista em Qualidade Magalu.\n"
            "Sua tarefa √© realizar uma ANALISE T√âCNICA E CIR√öRGICA da calibragem:\n\n"
            "1. COMPARE o Roteiro Original (IA) com o Roteiro Final (Aprovado pelo Humano).\n"
            "2. CALCULE o SCORE (%) de aproveitamento real seguindo esta R√âGUA ORG√ÇNICA MAGALU:\n"
            "   - 100%: Perfeito. O humano fez apenas ajustes de formata√ß√£o, pontua√ß√£o ou troca de conectivos sem alterar a ess√™ncia.\n"
            "   - 85% a 95%: Ajustes de Estilo. O humano melhorou a fluidez, encurtou frases ou trocou jarg√µes por termos mais comerciais.\n"
            "   - 60% a 80%: Mudan√ßa Estrutural. O humano adicionou informa√ß√µes faltantes, reconstruiu a abertura/fechamento ou cortou blocos inteiros.\n"
            "   - Abaixo de 60%: Erro Grave. A IA errou feio o tom de voz, omitiu funcionalidades vitais ou errou o SKU.\n"
            "   ATEN√á√ÉO: Termos presentes no C√ìDIGO SUGERIDO ou NOME DO PRODUTO (ex: 'Aro 26', 'Grau', 'Index') N√ÉO S√ÉO ERROS DA IA, n√£o penalize a nota por eles.\n"
            "3. S√çNTESE DE APRENDIZADO (MEM√ìRIA T√âCNICA): Transforme as edi√ß√µes do humano em DIRETRIZES T√ÅTICAS UNIVERSAIS para uma futura IA Redatora.\n"
            "   A diretriz DEVE ser escrita como uma regra de copywriting comercial, n√£o como uma descri√ß√£o do que aconteceu no produto X ou Y.\n"
            "   - REGRA ANTI-ALUCINA√á√ÉO E GENERALIZA√á√ÉO: √â ESTRITAMENTE PROIBIDO citar especifica√ß√µes do produto (ex: '85W de pot√™ncia', 'tela de 6 polegadas') na REGRA EM SI. O produto deve aparecer APENAS dentro de par√™nteses como o exemplo pr√°tico.\n"
            "   - COMECE COM VERBOS IMPERATIVOS: 'Integrar', 'Eliminar', 'Simplificar', 'Encurtar', 'Adotar', 'Reordenar', 'Focar'.\n"
            "   - ERRADO: 'Eliminou 85W de pot√™ncia mantendo 3 velocidades na cena 1'. (Muito espec√≠fico, in√∫til para outros produtos).\n"
            "   - CERTO: '- Remover especifica√ß√µes t√©cnicas iniciais como pot√™ncia para priorizar features funcionais e benef√≠cios pr√°ticos. (Ex: Na abertura, eliminou \"85W de pot√™ncia\" mantendo \"3 velocidades\").'\n"
            "   - ERRADO: 'Tirou v√°rios modos de funcionamento e colocou v√°rias fun√ß√µes'.\n"
            "3. APRENDIZADO GERAL (T√ÅTICO): Extraia REGRAS DIRETAS de reda√ß√£o (o que fazer e o que n√£o fazer). "
            "   NUNCA inclua regras visuais, descri√ß√µes de imagens ou coisas da tela aqui. Jogue essas na regra 10 ('imagens_regras').\n"
            "   Seja curto, grosso e imperativo, mas SEMPRE D√ä O EXEMPLO DO PRODUTO ATUAL DENTRO DE (Ex: ...). Use t√≥picos com '-'.\n"
            "4. EXTRAIA O C√ìDIGO DO PRODUTO (SKU): Procure no texto por sequ√™ncias num√©ricas ou o c√≥digo fornecido.\n"
            "5. CATEGORIZE (CR√çTICO): Escolha a melhor categoria da lista abaixo baseada na FUN√á√ÉO PRINCIPAL DO PRODUTO. "
            "N√£o se confunda com funcionalidades extras (ex: um monitor gamer com alto-falante √© 'Informatica / Gamer', e NUNCA '√Åudio'). "
            "Leia o texto com aten√ß√£o para identificar a ess√™ncia do produto.\n"
            "6. FON√âTICA (AUTO-EXTRA√á√ÉO): Se houver diferen√ßas entre a IA e o HUMANO na pron√∫ncia (par√™nteses ex: '(fl√≠ker fr√≠)'). "
            "Aten√ß√£o: 'termo_errado' = EXATAMENTE COMO A IA TINHA ESCRITO (ex: 'New Ortotech' sem pron√∫ncia). 'termo_corrigido' = EXATAMENTE COMO O HUMANO DEIXOU (ex: 'New Ortotech (niu √≥rtotec)'). Cuidado para n√£o inverter quem escreveu o qu√™! Se n√£o houver, retorne [].\n"
            "7. ESTRUTURAS (GANCHOS E CTAS): EXTRAIA OBRIGATORIAMENTE a Abertura (o Gancho inicial / primeira fala da Lu) e o Fechamento (o CTA final / √∫ltima fala da Lu) presentes no ROTEIRO FINAL (HUMANO). "
            "Isso √© CR√çTICO para termos uma biblioteca de 'Hooks' e 'Call to Actions' aprovados. "
            "Coloque no campo 'estrutura_regras'. Cada regra tem: "
            "'tipo' ('Abertura' ou 'Fechamento') e 'texto_ouro' (a frase exata encontrada no roteiro final). Se nenhuma estrutura for encontrada no roteiro final, retorne [].\n"
            "8. PERSONA LU (AUTO-EXTRA√á√ÉO): Se o humano corrigiu o TOM DE VOZ, ESTILO ou VOCABUL√ÅRIO da Lu, "
            "extraia como regras no campo 'persona_regras'. Cada regra tem: "
            "'pilar' (tom, vocabul√°rio, gancho, emo√ß√£o, clareza), 'erro' (o que a IA fez de errado), "
            "'correcao' (como o humano corrigiu) e 'lexico' (palavras-chave ou termos prefer√≠veis identificados na corre√ß√£o). "
            "Se N√ÉO houver corre√ß√µes de persona, retorne lista vazia [].\n"
            "9. RESUMO ESTRAT√âGICO (META-AN√ÅLISE): No campo 'resumo_estrategico', escreva um par√°grafo curto sintetizando a 'Dire√ß√£o Criativa' que o humano est√° tomando. "
            "Se n√£o houver mudan√ßa criativa, escreva 'O roteiro manteve a dire√ß√£o criativa da IA.'\n"
            "10. DESCRI√á√ÉO DE IMAGENS (VISUAL - ALERTA CR√çTICO): √â PROIBIDO COLOCAR FEEDBACKS VISUAIS NO 'aprendizado' DA REGRA 3. "
            "LADO A LADO, compare as linhas que come√ßam com 'Imagem:' na vers√£o da IA e do Humano. "
            "Se o humano detalhou ou alterou os elementos visuais da cena ou da tela, extraia OBRIGATORIAMENTE em 'imagens_regras'. "
            "Cada regra tem: 'antes' (a imagem gerada pela IA), 'depois' (a imagem ditada pelo humano) e 'motivo' (por que o humano mudou a dire√ß√£o de arte/c√¢mera). "
            "SE N√ÉO EXISTIREM ALTERA√á√ïES NAS IMAGENS, retorne uma lista vazia [].\n\n"
            "LISTA DE CATEGORIAS DISPON√çVEIS:\n"
            f"{cat_str}\n\n"
            "üö® REGRA CR√çTICA DE FORMATA√á√ÉO DE SA√çDA:\n"
            "Voc√™ √© um rob√¥ de extra√ß√£o de dados Puros. Retorne EXCLUSIVAMENTE o conte√∫do JSON abaixo.\n"
            "- NENHUM TEXTO ANTES OU DEPOIS DO JSON.\n"
            "- SEM PENSAMENTOS (tags <think> s√£o proibidas na resposta final).\n"
            "- N√ÉO use blocos de c√≥digo markdown (```json ... ```).\n"
            "- Inicie OBRIGATORIAMENTE with { e termine OBRIGATORIAMENTE with }.\n\n"
            "Formato exato:\n"
            "{\n"
            "  \"percentual\": <inteiro 0-100>,\n"
            "  \"aprendizado\": \"<diretrizes t√°ticas de escrita em t√≥picos>\",\n"
            "  \"resumo_estrategico\": \"<an√°lise da tend√™ncia criativa detectada>\",\n"
            "  \"categoria_id\": <id num√©rico da melhor categoria>,\n"
            "  \"codigo_produto\": \"<c√≥digo encontrado no texto ou o original>\",\n"
            "  \"fonetica_regras\": [{\"termo_errado\": \"...\", \"termo_corrigido\": \"...\", \"exemplo\": \"...\"}],\n"
            "  \"estrutura_regras\": [{\"tipo\": \"Abertura\", \"texto_ouro\": \"...\"}],\n"
            "  \"persona_regras\": [{\"pilar\": \"...\", \"erro\": \"...\", \"correcao\": \"...\", \"lexico\": \"...\"}],\n"
            "  \"imagens_regras\": [{\"antes\": \"...\", \"depois\": \"...\", \"motivo\": \"...\"}]\n"
            "}"
        )

        user_prompt = f"--- C√ìDIGO SUGERIDO ---\n{codigo_original}\n\n--- ROTEIRO ORIGINAL (IA) ---\n{original}\n\n--- ROTEIRO FINAL (HUMANO) ---\n{final}"

        # Usar Gemini 3 Flash Preview como mestre absoluto de Calibragem para todos os cen√°rios
        api_key_gemini = os.environ.get("GEMINI_API_KEY")
        if api_key_gemini:
            try:
                print("[TRY] Tentando calibragem via Gemini (3-flash-preview)...")
                genai_v1.configure(api_key=api_key_gemini)
                model_v1 = genai_v1.GenerativeModel('gemini-3-flash-preview')
                
                # Prompt de sistema + usu√°rio combinados (v1)
                full_prompt = f"{sys_prompt}\n\n{user_prompt}"
                
                response = model_v1.generate_content(
                    full_prompt,
                    generation_config=genai_v1.types.GenerationConfig(
                        temperature=0.1,
                    )
                )
                res = self._extract_json(response.text)
                print("[OK] Calibragem realizada via Gemini (3-flash-preview)")
                return self._process_calib_res(res, fallback_id, categories_list, codigo_original, "Gemini 3 Flash Preview (via Google)")
            except Exception as e:
                print(f"[ERROR] Erro Gemini Calibragem: {e}")

        print("[CRITICAL ERROR] FALHA TOTAL: Nenhum provedor de IA conseguiu realizar a calibragem.")
        return {"percentual": 50, "aprendizado": "Erro: Nenhum provedor de IA dispon√≠vel para calibragem.", "categoria_id": fallback_id, "codigo_produto": codigo_original, "modelo_calibragem": "N/A", "fonetica_regras": [], "estrutura_regras": [], "persona_regras": []}

    def _process_calib_res(self, res, fallback_id, categories_list, codigo_original, modelo_calibragem="N/A"):
        """Helper para processar e validar o JSON retornado pelos provedores."""
        # Valida√ß√£o rigorosa do ID de categoria
        returned_id = int(res.get("categoria_id", fallback_id)) if str(res.get("categoria_id")).isdigit() else fallback_id
        valid_ids = [c['id'] for c in categories_list] if categories_list else []
        
        # Se for 1 (antigo default errado) for√ßa pra Gen√©rico (77) ou o primeiro v√°lido
        if returned_id == 1 and 1 not in valid_ids:
            final_cat_id = 77 if 77 in valid_ids else (valid_ids[0] if valid_ids else fallback_id)
        else:
            final_cat_id = returned_id if returned_id in valid_ids else fallback_id

        
        import re
        sku_raw = str(res.get("codigo_produto", codigo_original))
        # SKUs Magalu tem EXATAMENTE 9 d√≠gitos. Priorizamos encontrar esses blocos.
        skus_found = re.findall(r'\b\d{9}\b', sku_raw)
        # Se n√£o achar blocos isolados, tenta achar qualquer sequ√™ncia de 9 d√≠gitos
        if not skus_found:
            skus_found = re.findall(r'\d{9}', sku_raw)
            
        sku_clean = " ".join(skus_found) if skus_found else re.sub(r'\D', '', sku_raw)
        
        return {
            "percentual": int(res.get("percentual", 50)),
            "aprendizado": res.get("aprendizado", "An√°lise realizada."),
            "categoria_id": final_cat_id,
            "codigo_produto": sku_clean,
            "modelo_calibragem": modelo_calibragem,
            "fonetica_regras": res.get("fonetica_regras", []),
            "estrutura_regras": res.get("estrutura_regras", []),
            "persona_regras": res.get("persona_regras", [])
        }

    def chat_with_context(self, user_query, chat_history=[], supabase_context=None):
        """
        Gera uma resposta conversacional baseada no hist√≥rico de chat e,
        opcionalmente, injeta dados recentes do Supabase (RAG-lite) no prompt.
        """
        system_base = (
            "Voc√™ √© a Lu, a assistente virtual inteligente e especialista em IA da Magalu. "
            "Sua miss√£o √© ajudar a equipe interna exclusivamente com: cria√ß√£o de roteiros de v√≠deo, reda√ß√£o publicit√°ria, an√°lise de qualidade (calibragem) e d√∫vidas sobre esta su√≠te de IA. "
            "REGRA DE OURO M√ÅXIMA: √â PROIBIDO responder perguntas fora do contexto da Magalu, tecnologia em varejo, reda√ß√£o ou sobre o sistema de roteiros. Se o assunto sair disso, responda educadamente que voc√™ s√≥ pode ajudar com demandas de conte√∫do da Magalu. "
            "Tenha um tom acolhedor ('estilo magalu'), direto ao ponto, e use emojis ocasionalmente.\n\n"
        )
        
        if supabase_context:
            system_base += f"--- CONTEXTO ATUAL DO BANCO DE DADOS ---\n{supabase_context}\n---------------------------------------\n"

        try:
            if self.provider == "gemini":
                # Para o Gemini (SDK v1), montaremos a interface como um string prompt 
                # contendo o system prompt + hist√≥rico + pergunta
                full_prompt = system_base + "\n\n--- HIST√ìRICO RECENTE ---\n"
                for msg in chat_history[-6:]: 
                    r = msg.get('role', 'user').upper()
                    c = msg.get('content', '')
                    full_prompt += f"{r}: {c}\n"
                full_prompt += f"\nUSU√ÅRIO: {user_query}\nLU:"
                
                response = self.client_gemini.models.generate_content(
                    model=self.model_id,
                    contents=full_prompt,
                    config={"temperature": 0.5}
                )
                return response.text
                
            elif self.provider in ["openai", "puter", "openrouter", "zai", "kimi"]:
                messages = [{"role": "system", "content": system_base}]
                for msg in chat_history[-6:]:
                    r = "assistant" if msg.get("role") == "Lu" else "user"
                    messages.append({"role": r, "content": msg["content"]})
                    
                messages.append({"role": "user", "content": user_query})
                
                response = self.client_openai.chat.completions.create(
                    model=self.model_id,
                    messages=messages,
                    temperature=0.7
                )
                return response.choices[0].message.content
                
            else:
                return "Provedor LLM n√£o reconhecido para Chat."
                
        except Exception as e:
            return f"Desculpe, tive um problema t√©cnico ao conectar com a IA ({self.model_id}): {e}"

    def otimizar_roteiros(self, roteiros_textos: list, codigo: str, nome_produto: str, ficha_tecnica: str = None) -> dict:
        """
        Sintetiza de 2 a 5 roteiros selecionados escolhendo os melhores ganchos, argumentos e fechamentos,
        mantendo o tom de voz da marca e o formato estrito NW LU.
        """
        # Formata os roteiros para o prompt
        roteiros_formatados = ""
        for i, roteiro in enumerate(roteiros_textos):
            roteiros_formatados += f"--- VERS√ÉO {i + 1} ---\n{roteiro}\n\n"
            
        sys_prompt = (
            "Voc√™ √© o Diretor de Cria√ß√£o S√™nior da Magalu. Especialista em juntar boas ideias.\n"
            "Eu vou te apresentar algumas vers√µes de roteiros gerados por diferentes IAs para o mesmo produto.\n"
            "Sua tarefa: Sintetize o M√ÅXIMO da capacidade publicit√°ria dessas vers√µes, RETORNANDO UM √öNICO ROTEIRO DEFINITIVO QUE SEJA A 'MELHOR VERS√ÉO'.\n\n"
            "DIRETRIZES DE S√çNTESE:\n"
            "- ABERTURA IMPACTANTE: Escolha o gancho (hook) inicial mais forte e criativo entre as vers√µes.\n"
            "- ARGUMENTA√á√ÉO S√ìLIDA: Pegue a melhor explica√ß√£o t√©cnica e os benef√≠cios mais persuasivos de cada um.\n"
            "- FECHAMENTO AFIADO: Escolha a melhor CTA e fechamento em tom de voz 'Lu do Magalu'.\n"
            "- FLUIDEZ E RITMO: O texto final deve soar natural, sem retalhos.\n"
            "- COMPARA√á√ÉO COM A FICHA T√âCNICA: Verifique a ficha t√©cnica fornecida e garanta que nenhuma informa√ß√£o vital (acess√≥rios, voltagem, caracter√≠stica principal) foi esquecida pelas outras IAs.\n"
            "- REGRA DE CABE√áALHO: O roteiro final DEVE preservar a estrutura EXATA de cabe√ßalho NW LU (Cliente, Roteirista, Data, Produto). NUNCA use negrito (**) no cabe√ßalho.\n\n"
            "Se voc√™ n√£o encontrar a ficha t√©cnica, confie apenas nas informa√ß√µes dadas pelas vers√µes."
        )

        ficha_prompt = f"--- FICHA T√âCNICA ORIGINAL ---\n{ficha_tecnica}\n\n" if ficha_tecnica else ""
        user_prompt = f"C√≥digo: {codigo}\nProduto: {nome_produto}\n\n{ficha_prompt}{roteiros_formatados}\n\nPor favor, retorne O ROTEIRO DEFINITIVO (MELHOR VERS√ÉO) seguindo a formata√ß√£o padr√£o NW LU. Sem pre√¢mbulos, texto direto."

        contents = [
            sys_prompt,
            user_prompt
        ]

        if self.client_gemini:
            response = self.client_gemini.generate_content(contents)
            roteiro = response.text
            tokens_in = len(str(contents)) // 4
            tokens_out = len(roteiro) // 4
        elif self.client_openai:
            messages = [
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_prompt}
            ]
            response = self.client_openai.chat.completions.create(
                model=self.model_id,
                messages=messages
            )
            roteiro = response.choices[0].message.content
            tokens_in = response.usage.prompt_tokens if hasattr(response, 'usage') else 0
            tokens_out = response.usage.completion_tokens if hasattr(response, 'usage') else 0
        else:
            raise Exception("Nenhum cliente LLM configurado v√°lido.")

        custo_brl = calcular_custo_brl(self.model_id, tokens_in, tokens_out)

        return {
            "roteiro": roteiro,
            "model_id": f"{self.model_id} (Otimizado)",
            "tokens_in": tokens_in,
            "tokens_out": tokens_out,
            "custo_brl": custo_brl
        }
